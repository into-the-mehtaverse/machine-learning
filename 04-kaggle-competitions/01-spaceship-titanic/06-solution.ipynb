{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7097cd6f-cb7f-4ff3-8037-7280db56b0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GroupKFold\n",
    "from sklearn.ensemble import RandomForestClassifier, HistGradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "df_train = pd.read_csv(\"data/train.csv\")\n",
    "df_test = pd.read_csv(\"data/test.csv\")\n",
    "sample_submission = pd.read_csv(\"data/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca89b64b-164e-47d3-b66d-7df489a6d7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## add TotalSpend numeric feature and NoSpend numeric feature\n",
    "\n",
    "for df in (df_train, df_test):\n",
    "    # Sum all the spending columns\n",
    "    df[\"TotalSpend\"] = (\n",
    "        df[\"RoomService\"]\n",
    "        + df[\"FoodCourt\"]\n",
    "        + df[\"ShoppingMall\"]\n",
    "        + df[\"Spa\"]\n",
    "        + df[\"VRDeck\"]\n",
    "    )\n",
    "\n",
    "    # Optional: flag for passengers who spent nothing\n",
    "    df[\"NoSpend\"] = (df[\"TotalSpend\"] == 0).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef0a396b-230c-42d3-a454-cd63d1c263f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split cabin feature into three, for deck, floor and side\n",
    "\n",
    "for df in (df_train, df_test):\n",
    "    cabin_split = df[\"Cabin\"].str.split(\"/\", expand=True)\n",
    "\n",
    "    df[\"CabinDeck\"] = cabin_split[0]                      # e.g. \"B\"\n",
    "    df[\"CabinNum\"] = pd.to_numeric(cabin_split[1], errors=\"coerce\")  # e.g. 45\n",
    "    df[\"CabinSide\"] = cabin_split[2]                      # e.g. \"P\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d973475-f2a0-4719-af82-0e6785aacc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "## exploit groups\n",
    "\n",
    "for df in (df_train, df_test):\n",
    "    df[\"GroupId\"] = df[\"PassengerId\"].str.split(\"_\").str[0]\n",
    "    group_sizes = df.groupby(\"GroupId\")[\"GroupId\"].transform(\"count\")\n",
    "    df[\"GroupSize\"] = group_sizes\n",
    "    df[\"IsAlone\"] = (df[\"GroupSize\"] == 1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36baa688-9160-4296-831d-88b65529807b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## BELOW WE WILL DEFINE THE COLUMNS FROM THE DATA SET \n",
    "## AND CREATE FIT_PREPROCESSING\n",
    "target_col = \"Transported\"\n",
    "drop_cols = [\"PassengerId\", \"Name\", \"Cabin\"]\n",
    "numeric_cols = [\"Age\", \"RoomService\", \"FoodCourt\", \"ShoppingMall\", \"Spa\", \"VRDeck\", \"TotalSpend\", \"NoSpend\", \"CabinNum\", \"GroupSize\", \"IsAlone\"]\n",
    "categorical_cols = [\"HomePlanet\", \"CryoSleep\", \"CabinDeck\", \"CabinSide\", \"Destination\", \"VIP\"]\n",
    "\n",
    "def fit_preprocessing (df_train):\n",
    "    y = df_train[target_col].astype(int)\n",
    "    X = df_train.drop(columns=drop_cols + [target_col])\n",
    "\n",
    "    X_numeric = X[numeric_cols].copy()\n",
    "    X_cat = X[categorical_cols].copy()\n",
    "\n",
    "    numeric_medians = X_numeric.median()\n",
    "    cat_modes = X_cat.mode().iloc[0]\n",
    "    \n",
    "    ## add in median for NaNs on numerical cols\n",
    "    for col in numeric_cols:\n",
    "        X_numeric[col] = X_numeric[col].fillna(numeric_medians[col])\n",
    "\n",
    "    for col in categorical_cols:\n",
    "        X_cat[col] = X_cat[col].fillna(cat_modes[col])\n",
    "\n",
    "    if X_numeric.isna().sum().sum() != 0:\n",
    "        print(\"Error: not null values in numeric cols still unfilled\")\n",
    "        return\n",
    "\n",
    "    if X_cat.isna().sum().sum() != 0:\n",
    "        print(\"Error: not null values still in cat. calls still unfilled\")\n",
    "        return\n",
    "\n",
    "    X_cat_encoded = pd.get_dummies(X_cat, drop_first=False)  \n",
    "    \n",
    "    X_prepared = pd.concat([X_numeric, X_cat_encoded], axis=1)\n",
    "    print(X_prepared.shape)\n",
    "\n",
    "    return X_prepared, numeric_medians, cat_modes, y, X_prepared.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d8d97b3-f25a-40be-a0e6-45beceff139a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_preprocessing(df, numeric_medians, cat_modes, train_cols):\n",
    "    X = df.drop(columns=drop_cols)\n",
    "\n",
    "    X_numeric = X[numeric_cols].copy()\n",
    "    X_cat = X[categorical_cols].copy()\n",
    "\n",
    "    for col in numeric_cols:\n",
    "        X_numeric[col] = X_numeric[col].fillna(numeric_medians[col])\n",
    "\n",
    "    for col in categorical_cols:\n",
    "        X_cat[col] = X_cat[col].fillna(cat_modes[col])\n",
    "\n",
    "    if X_numeric.isna().sum().sum() != 0:\n",
    "        print(\"Error: null values in numeric cols still unfilled\")\n",
    "        return\n",
    "\n",
    "    if X_cat.isna().sum().sum() != 0:\n",
    "        print(\"Error: null values still in cat. calls still unfilled\")\n",
    "        return\n",
    "\n",
    "    X_cat_encoded = pd.get_dummies(X_cat, drop_first=False)\n",
    "\n",
    "    X_prepared = pd.concat([X_numeric, X_cat_encoded], axis=1)\n",
    "\n",
    "    X_prepared = X_prepared.reindex(columns=train_cols, fill_value=0)\n",
    "\n",
    "    return X_prepared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9a66f57-c4a6-4cae-b5f9-63b2f1713e16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8693, 29)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0q/q3ls96hn7q7c5f2kxhnz3pf00000gn/T/ipykernel_45831/4281073105.py:23: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X_cat[col] = X_cat[col].fillna(cat_modes[col])\n",
      "/var/folders/0q/q3ls96hn7q7c5f2kxhnz3pf00000gn/T/ipykernel_45831/3688511642.py:11: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X_cat[col] = X_cat[col].fillna(cat_modes[col])\n"
     ]
    }
   ],
   "source": [
    "X_prepared, numeric_medians, cat_modes, y, train_cols = fit_preprocessing(df_train)\n",
    "X_test_prepared = apply_preprocessing(df_test, numeric_medians, cat_modes, train_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c2269e1-9c6c-4d91-8e42-0e36c67396a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_prepared, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a27fd4b-e666-4245-bdcb-83eda48abcad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thr=0.40 -> mean_acc=0.80916\n",
      "thr=0.41 -> mean_acc=0.80996\n",
      "thr=0.42 -> mean_acc=0.81077\n",
      "thr=0.43 -> mean_acc=0.81111\n",
      "thr=0.44 -> mean_acc=0.81042\n",
      "thr=0.45 -> mean_acc=0.81054\n",
      "thr=0.46 -> mean_acc=0.81123\n",
      "thr=0.47 -> mean_acc=0.81123\n",
      "thr=0.48 -> mean_acc=0.81134\n",
      "thr=0.49 -> mean_acc=0.81065\n",
      "thr=0.50 -> mean_acc=0.80996\n",
      "thr=0.51 -> mean_acc=0.80766\n",
      "thr=0.52 -> mean_acc=0.80697\n",
      "thr=0.53 -> mean_acc=0.80789\n",
      "thr=0.54 -> mean_acc=0.80720\n",
      "thr=0.55 -> mean_acc=0.80525\n",
      "thr=0.56 -> mean_acc=0.80548\n",
      "thr=0.57 -> mean_acc=0.80617\n",
      "thr=0.58 -> mean_acc=0.80674\n",
      "thr=0.59 -> mean_acc=0.80582\n",
      "thr=0.60 -> mean_acc=0.80364\n",
      "Best threshold: 0.48 with CV acc: 0.8113416503936298\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "import numpy as np\n",
    "\n",
    "groups = df_train[\"GroupId\"]\n",
    "\n",
    "gkf = GroupKFold(n_splits=5)\n",
    "\n",
    "thresholds = np.linspace(0.4, 0.6, 21)  # 0.40, 0.41, ..., 0.60\n",
    "\n",
    "best_thr = None\n",
    "best_acc = -1\n",
    "\n",
    "for thr in thresholds:\n",
    "    fold_accs = []\n",
    "\n",
    "    for train_idx, val_idx in gkf.split(X_prepared, y, groups=groups):\n",
    "        X_tr, X_va = X_prepared.iloc[train_idx], X_prepared.iloc[val_idx]\n",
    "        y_tr, y_va = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "        gb = HistGradientBoostingClassifier(\n",
    "            learning_rate=0.05,\n",
    "            max_depth=None,\n",
    "            max_iter=300,\n",
    "            min_samples_leaf=20,\n",
    "            random_state=42,\n",
    "        )\n",
    "        gb.fit(X_tr, y_tr)\n",
    "        proba_va = gb.predict_proba(X_va)[:, 1]\n",
    "\n",
    "        preds_va = (proba_va >= thr).astype(int)\n",
    "        acc = accuracy_score(y_va, preds_va)\n",
    "        fold_accs.append(acc)\n",
    "\n",
    "    mean_acc = np.mean(fold_accs)\n",
    "    print(f\"thr={thr:.2f} -> mean_acc={mean_acc:.5f}\")\n",
    "\n",
    "    if mean_acc > best_acc:\n",
    "        best_acc = mean_acc\n",
    "        best_thr = thr\n",
    "\n",
    "print(\"Best threshold:\", best_thr, \"with CV acc:\", best_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1455aad-151e-48a1-a5be-a6b3a977ea14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# 1. Train final HGB on all training data\n",
    "gb_final = HistGradientBoostingClassifier(\n",
    "    learning_rate=0.05,\n",
    "    max_depth=None,\n",
    "    max_iter=300,\n",
    "    min_samples_leaf=20,\n",
    "    random_state=42,\n",
    ")\n",
    "gb_final.fit(X_prepared, y)\n",
    "\n",
    "# 2. Predict probabilities on test\n",
    "proba_test = gb_final.predict_proba(X_test_prepared)[:, 1]\n",
    "\n",
    "# 3. Use tuned threshold instead of 0.5\n",
    "best_thr = 0.48  # <-- replace with the value you found from the sweep\n",
    "pred_test = (proba_test >= best_thr).astype(bool)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    \"PassengerId\": df_test[\"PassengerId\"],\n",
    "    \"Transported\": pred_test,\n",
    "})\n",
    "\n",
    "os.makedirs(\"submissions\", exist_ok=True)\n",
    "submission.to_csv(\"submissions/06_hgb_threshold_tuned.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b0068c-8f07-40e5-bb5d-79402539a831",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
